{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:which model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Outcome variable is of type float and this leads us to looking for a regressor model.The next question is what do we care most speed or accuracy when chosing our model,if speed then Decision tree or Linear regression will do the job.ofcourse we need to compare their accuracy for best model between the two.But if we care most about accuracy then either Random forest or Gradient boosting will are preferable as a general rule.The data size seems to be small,i would personaly choose Linear rigression at the first sight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. You have more features (columns) than rows in your dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there will be an issue of overfitting for our model and to combat this we need to look for a model that integrates Regularization cost function such as Lasso Regression when the outcome is float. But Generally we can apply kernel SVM or Random Forest or Gradiant boosting for both regression and classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Identify the most important characteristic predicting likelihood of being jailed before age 20.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means identifying the most important features in influencing the likelihood of being jailed before age 20.When our characteristic variable is float then running correlation matrix of the variable with the outcome variable(likelihood) and selecting variables with high correlation coefficient.Or we can use principal component analysis algorism.when the characteristic are categorical however we can use chi-square test of independence to determine the relationship between every characteistic and the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Implement a filter to “highlight” emails that might be important to the recipient.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i would chose Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. You have 1000+ features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if classification and we care more about speed then Naive Bayes is good to go.\n",
    "- If regression, Lasso Regression will be a good choice as it has a feature selection mechanism.\n",
    "\n",
    "We can use different models however depending on other important facotrs such as speed and accuracy as long as we can implement a good feature selection and dimentionality reduction methods such as Principal Component analysis(PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Predict whether someone who adds items to their cart on a website will purchase the items.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In selecting machine learning models,the key ingradients are speed and accuracy.When it comes to accuracy in this case chosing either Random Forest or support Vector Machine or Gradient Boosting classifiers will do the job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Your dataset dimensions are 982400 x 500**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite high dimention and dimentionality reduction methods such as PCA and Component Analysis methodologies will help in the future selection phase of the analysis.and we determine our model based on the characteristic of our data and outcome variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Identify faces in an image.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes classifier will do the trick in Identify faces in an image it computes the probability of a face to be present in the picture by counting the frequency of occurrence of a series of the pattern over the training images. The classifier captures the joint statistics of local appearance and position of the faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Predict which of three flavors of ice cream will be most popular with boys vs girls.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes.Because we will calculate the prediction based on the conditional probability of the flavours consumed by each gender in our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------- End ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
