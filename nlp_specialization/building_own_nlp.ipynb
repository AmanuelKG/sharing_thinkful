{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP SUPERVISED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "[The King James Bible]\n",
      "\n",
      "The Old Testament of the King James Bible\n",
      "\n",
      "The First Book of Moses:  Called Genesis\n",
      "\n",
      "\n",
      "1:1 In the beginning God created the heaven and the earth.\n",
      "\n",
      "1:2 And the earth was without form, and void; and darkness was upon\n",
      "the face of the deep. And the Spirit of God moved upon the face of the\n",
      "waters.\n",
      "\n",
      "1:3 And God said, Let there be light: and there was light.\n",
      "\n",
      "1:4 And God saw the light, that it was good: and God divided the light\n",
      "from the darkness.\n",
      "\n",
      "1:5 And God called the light Da\n",
      "[Paradise Lost by John Milton 1667] \n",
      " \n",
      " \n",
      "Book I \n",
      " \n",
      " \n",
      "Of Man's first disobedience, and the fruit \n",
      "Of \n"
     ]
    }
   ],
   "source": [
    "# Grab and process the raw data.\n",
    "print(gutenberg.fileids())\n",
    "bible = gutenberg.raw('bible-kjv.txt')\n",
    "paradise = gutenberg.raw('milton-paradise.txt')\n",
    "print(bible[0:500])\n",
    "print(paradise[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "bible = re.sub(r'\\d:*', '', bible)\n",
    "bible = re.sub(r',:', '', bible)\n",
    "paradise = re.sub(r'Book .*', '', paradise)\n",
    "\n",
    "paradise = text_cleaner(paradise[:int(len(paradise)/10)])\n",
    "bible = text_cleaner(bible[:int(len(bible)/50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "paradise_doc = nlp(paradise)\n",
    "bible_doc = nlp(bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>(And, Isaac, went, out, to, meditate, in, the,...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>(And, Rebekah, lifted, up, her, eyes, ,, and, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>(For, she, had, said, unto, the, servant, ,, W...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>(And, the, servant, had, said, ,)</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>(It, is, my, master, :, t)</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0      1\n",
       "1033  (And, Isaac, went, out, to, meditate, in, the,...  bible\n",
       "1034  (And, Rebekah, lifted, up, her, eyes, ,, and, ...  bible\n",
       "1035  (For, she, had, said, unto, the, servant, ,, W...  bible\n",
       "1036                  (And, the, servant, had, said, ,)  bible\n",
       "1037                         (It, is, my, master, :, t)  bible"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "bible_sents = [[sent, \"bible\"] for sent in bible_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(paradise_sents + bible_sents)\n",
    "sentences.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "paradisewords = bag_of_words(paradise_doc)\n",
    "biblewords = bag_of_words(bible_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(paradisewords + biblewords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Creation using the BoW Method\n",
    "In This method features are common words on the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n",
      "Processing row 500\n",
      "Processing row 550\n",
      "Processing row 600\n",
      "Processing row 650\n",
      "Processing row 700\n",
      "Processing row 750\n",
      "Processing row 800\n",
      "Processing row 850\n",
      "Processing row 900\n",
      "Processing row 950\n",
      "Processing row 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Rehoboth</th>\n",
       "      <th>wile</th>\n",
       "      <th>battlement</th>\n",
       "      <th>wilt</th>\n",
       "      <th>fight</th>\n",
       "      <th>obey</th>\n",
       "      <th>renown</th>\n",
       "      <th>suggestion</th>\n",
       "      <th>frequent</th>\n",
       "      <th>...</th>\n",
       "      <th>abroad</th>\n",
       "      <th>whale</th>\n",
       "      <th>hurl</th>\n",
       "      <th>grave</th>\n",
       "      <th>aileth</th>\n",
       "      <th>expatiate</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>Danaw</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Of, Man, 's, first, disobedience, ,, and, the...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(,, I, thence, Invoke, thy, aid, to, my, adven...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, chiefly, thou, ,, O, Spirit, ,, that, do...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(outspread, ,, Dove, -, like, sat'st, brooding...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(it, pregnant, :, what, in, me, is, dark, Illu...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accept Rehoboth wile battlement wilt fight obey renown suggestion frequent  \\\n",
       "0      0        0    0          0    0     0    0      0          0        0   \n",
       "1      0        0    0          0    0     0    0      0          0        0   \n",
       "2      0        0    0          0    0     0    0      0          0        0   \n",
       "3      0        0    0          0    0     0    0      0          0        0   \n",
       "4      0        0    0          0    0     0    0      0          0        0   \n",
       "\n",
       "   ... abroad whale hurl grave aileth expatiate pregnant Danaw  \\\n",
       "0  ...      0     0    0     0      0         0        0     0   \n",
       "1  ...      0     0    0     0      0         0        0     0   \n",
       "2  ...      0     0    0     0      0         0        0     0   \n",
       "3  ...      0     0    0     0      0         0        0     0   \n",
       "4  ...      0     0    0     0      0         0        1     0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Of, Man, 's, first, disobedience, ,, and, the...      Milton  \n",
       "1  (,, I, thence, Invoke, thy, aid, to, my, adven...      Milton  \n",
       "2  (And, chiefly, thou, ,, O, Spirit, ,, that, do...      Milton  \n",
       "3  (outspread, ,, Dove, -, like, sat'st, brooding...      Milton  \n",
       "4  (it, pregnant, :, what, in, me, is, dark, Illu...      Milton  \n",
       "\n",
       "[5 rows x 2734 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 29.309532241506115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "y = word_counts['text_source']\n",
    "x = word_counts.drop(['text_source', 'text_sentence'], axis = 1)\n",
    "svd= TruncatedSVD(20)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "x_lsa = lsa.fit_transform(x)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_lsa, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(622, 20) (622,)\n",
      "Training set score: 0.9453376205787781\n",
      "\n",
      "Test set score: 0.9302884615384616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "train = lr.fit(x_train, y_train)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(x_train, y_train))\n",
    "print('\\nTest set score:', lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Creation using the tf-idf Method.\n",
    "In this method however the features are the sentences in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Paradise Lost by John Milton  ]', 'Book I', \"Of Man ' s first disobedience , and the fruit Of that forbidden tree whose mortal taste Brought death into the World , and all our woe , With loss of Eden , till one greater Man Restore us , and regain the blissful seat , Sing , Heavenly Muse , that , on the secret top Of Oreb , or of Sinai , didst inspire That shepherd who first taught the chosen seed In the beginning how the heavens and earth Rose out of Chaos : or , if Sion hill Delight thee more , and Siloa ' s brook that flowed Fast by the oracle of God , I thence Invoke thy aid to my adventurous song , That with no middle flight intends to soar Above th ' Aonian mount , while it pursues Things unattempted yet in prose or rhyme .\", 'Book II']\n"
     ]
    }
   ],
   "source": [
    "#reading in the data, this time in the form of paragraphs\n",
    "paradise_para = gutenberg.paras('milton-paradise.txt')\n",
    "bible_para=gutenberg.paras('bible-kjv.txt')\n",
    "\n",
    "paradise_paras=[]\n",
    "for paragraph in paradise_para:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    para = [re.sub(r'\\d*','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    paradise_paras.append(' '.join(para))\n",
    "print(paradise_paras[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ The King James Bible ]', 'The Old Testament of the King James Bible', 'The First Book of Moses : Called Genesis', ' :  In the beginning God created the heaven and the earth .']\n"
     ]
    }
   ],
   "source": [
    "bible_paras=[]\n",
    "for paragraph in bible_para:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    para = [re.sub(r'\\d*','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    bible_paras.append(' '.join(para))\n",
    "\n",
    "print(bible_paras[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 43\n"
     ]
    }
   ],
   "source": [
    "#importing the TfidfVectorizer which creates vectors of terms for each document.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "paradise_paras_tfidf=vectorizer.fit_transform(paradise_paras)\n",
    "paradise_features = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(paradise_paras_tfidf.get_shape()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 7880\n"
     ]
    }
   ],
   "source": [
    "#Applying the vectorizer\n",
    "bible_paras_tfidf=vectorizer.fit_transform(bible_paras)\n",
    "bible_features = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(bible_paras_tfidf.get_shape()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and colummns in paradise dataframe: (29, 43)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adam</th>\n",
       "      <th>angel</th>\n",
       "      <th>beginning</th>\n",
       "      <th>book</th>\n",
       "      <th>celestial</th>\n",
       "      <th>earth</th>\n",
       "      <th>eve</th>\n",
       "      <th>fixed</th>\n",
       "      <th>flight</th>\n",
       "      <th>fruit</th>\n",
       "      <th>...</th>\n",
       "      <th>thee</th>\n",
       "      <th>thou</th>\n",
       "      <th>thy</th>\n",
       "      <th>till</th>\n",
       "      <th>unblam</th>\n",
       "      <th>voice</th>\n",
       "      <th>waked</th>\n",
       "      <th>woe</th>\n",
       "      <th>world</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adam  angel  beginning  book  celestial  earth  eve  fixed  flight  fruit  \\\n",
       "0   0.0    0.0        0.0   0.0        0.0    0.0  0.0    0.0     0.0    0.0   \n",
       "1   0.0    0.0        0.0   1.0        0.0    0.0  0.0    0.0     0.0    0.0   \n",
       "2   0.0    0.0        0.2   0.0        0.0    0.2  0.0    0.0     0.2    0.2   \n",
       "3   0.0    0.0        0.0   1.0        0.0    0.0  0.0    0.0     0.0    0.0   \n",
       "4   0.0    0.0        0.0   0.0        0.2    0.0  0.0    0.2     0.0    0.0   \n",
       "\n",
       "   ...  thee  thou  thy  till  unblam  voice  waked  woe  world  authors  \n",
       "0  ...   0.0   0.0  0.0   0.0     0.0    0.0    0.0  0.0    0.0   Milton  \n",
       "1  ...   0.0   0.0  0.0   0.0     0.0    0.0    0.0  0.0    0.0   Milton  \n",
       "2  ...   0.2   0.0  0.2   0.2     0.0    0.0    0.0  0.2    0.2   Milton  \n",
       "3  ...   0.0   0.0  0.0   0.0     0.0    0.0    0.0  0.0    0.0   Milton  \n",
       "4  ...   0.0   0.0  0.0   0.0     0.0    0.0    0.0  0.0    0.0   Milton  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the term frequency matrix data to pandas data frame.\n",
    "paradise_paras_tfidf_df = pd.DataFrame(paradise_paras_tfidf.todense())\n",
    "paradise_paras_tfidf_df = paradise_paras_tfidf_df.round(1)\n",
    "#print the features as column names of the data frame.\n",
    "paradise_paras_tfidf_df.columns = paradise_features\n",
    "#create the labels\n",
    "paradise_label = pd.Series(data = 29*['Milton'])\n",
    "paradise_label = pd.DataFrame(paradise_label, columns = ['authors'])\n",
    "\n",
    "# The dimension of the paradise data frame\n",
    "print('Number of rows and colummns in paradise dataframe: {}'.format(paradise_paras_tfidf_df.shape))\n",
    "\n",
    "# #Lets concatnate the data column with the label\n",
    "paradise_paras_tfidf_df = pd.concat([paradise_paras_tfidf_df, paradise_label], axis = 1)\n",
    "paradise_paras_tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and colummns in bible dataframe: (24608, 7880)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronites</th>\n",
       "      <th>abarim</th>\n",
       "      <th>abase</th>\n",
       "      <th>abased</th>\n",
       "      <th>abated</th>\n",
       "      <th>abba</th>\n",
       "      <th>abda</th>\n",
       "      <th>abdi</th>\n",
       "      <th>abdon</th>\n",
       "      <th>...</th>\n",
       "      <th>zohar</th>\n",
       "      <th>zophah</th>\n",
       "      <th>zophar</th>\n",
       "      <th>zorah</th>\n",
       "      <th>zorobabel</th>\n",
       "      <th>zuar</th>\n",
       "      <th>zuph</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurishaddai</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  aaronites  abarim  abase  abased  abated  abba  abda  abdi  abdon  \\\n",
       "0    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "1    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "2    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "3    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "4    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "\n",
       "   ...  zohar  zophah  zophar  zorah  zorobabel  zuar  zuph  zur  zurishaddai  \\\n",
       "0  ...    0.0     0.0     0.0    0.0        0.0   0.0   0.0  0.0          0.0   \n",
       "1  ...    0.0     0.0     0.0    0.0        0.0   0.0   0.0  0.0          0.0   \n",
       "2  ...    0.0     0.0     0.0    0.0        0.0   0.0   0.0  0.0          0.0   \n",
       "3  ...    0.0     0.0     0.0    0.0        0.0   0.0   0.0  0.0          0.0   \n",
       "4  ...    0.0     0.0     0.0    0.0        0.0   0.0   0.0  0.0          0.0   \n",
       "\n",
       "   authors  \n",
       "0      kjv  \n",
       "1      kjv  \n",
       "2      kjv  \n",
       "3      kjv  \n",
       "4      kjv  \n",
       "\n",
       "[5 rows x 7881 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets follow the same procedure as the above paradise data and create our bible pandas dataframe.\n",
    "\n",
    "bible_paras_tfidf_df = pd.DataFrame(bible_paras_tfidf.todense())\n",
    "print('Number of rows and colummns in bible dataframe: {}'.format(bible_paras_tfidf_df.shape))\n",
    "bible_paras_tfidf_df.columns = bible_features\n",
    "bible_label = pd.Series(data = 24608 *['kjv'])\n",
    "bible_label = pd.DataFrame(bible_label, columns = ['authors'])\n",
    "bible_paras_tfidf_df = pd.concat([bible_paras_tfidf_df, bible_label], axis = 1)\n",
    "bible_paras_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([bible_paras_tfidf_df,paradise_paras_tfidf_df],ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronites</th>\n",
       "      <th>abarim</th>\n",
       "      <th>abase</th>\n",
       "      <th>abased</th>\n",
       "      <th>abated</th>\n",
       "      <th>abba</th>\n",
       "      <th>abda</th>\n",
       "      <th>abdi</th>\n",
       "      <th>abdon</th>\n",
       "      <th>...</th>\n",
       "      <th>zur</th>\n",
       "      <th>zurishaddai</th>\n",
       "      <th>authors</th>\n",
       "      <th>celestial</th>\n",
       "      <th>gorgeous</th>\n",
       "      <th>morn</th>\n",
       "      <th>rosy</th>\n",
       "      <th>soar</th>\n",
       "      <th>unblam</th>\n",
       "      <th>waked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kjv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  aaronites  abarim  abase  abased  abated  abba  abda  abdi  abdon  \\\n",
       "0    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "1    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "2    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "3    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "4    0.0        0.0     0.0    0.0     0.0     0.0   0.0   0.0   0.0    0.0   \n",
       "\n",
       "   ...  zur  zurishaddai  authors  celestial  gorgeous  morn  rosy  soar  \\\n",
       "0  ...  0.0          0.0      kjv        0.0       0.0   0.0   0.0   0.0   \n",
       "1  ...  0.0          0.0      kjv        0.0       0.0   0.0   0.0   0.0   \n",
       "2  ...  0.0          0.0      kjv        0.0       0.0   0.0   0.0   0.0   \n",
       "3  ...  0.0          0.0      kjv        0.0       0.0   0.0   0.0   0.0   \n",
       "4  ...  0.0          0.0      kjv        0.0       0.0   0.0   0.0   0.0   \n",
       "\n",
       "   unblam  waked  \n",
       "0     0.0    0.0  \n",
       "1     0.0    0.0  \n",
       "2     0.0    0.0  \n",
       "3     0.0    0.0  \n",
       "4     0.0    0.0  \n",
       "\n",
       "[5 rows x 7888 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = new_data['authors']\n",
    "X = new_data.drop('authors', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction and Dimension reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use SVD for exracting only important features from the high dimension data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 23.08566422332158\n"
     ]
    }
   ],
   "source": [
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_lsa = lsa.fit_transform(X)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD model with that amount of total components explains close to 66% of the total variance in the data.So lets go with it and move to supervised learning classification approach to identify if a paragraph is from the 'bible' text or the 'paradise' text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_lsa, Y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14782, 100) (14782,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9991205520227303\n",
      "\n",
      "Test set score: 0.9983764586504312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "Train = lr.fit(X_train, Y_train)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, Y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
