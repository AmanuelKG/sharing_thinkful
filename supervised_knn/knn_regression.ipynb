{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "music = pd.DataFrame()\n",
    "music['duration'] = [184, 134, 243, 186, 122, 197, 294, 382, 102, 264, \n",
    "                     205, 110, 307, 110, 397, 153, 190, 192, 210, 403,\n",
    "                     164, 198, 204, 253, 234, 190, 182, 401, 376, 102]\n",
    "music['loudness'] = [18, 34, 43, 36, 22, 9, 29, 22, 10, 24, \n",
    "                     20, 10, 17, 51, 7, 13, 19, 12, 21, 22,\n",
    "                     16, 18, 4, 23, 34, 19, 14, 11, 37, 42]\n",
    "music['bpm'] = [ 105, 90, 78, 75, 120, 110, 80, 100, 105, 60,\n",
    "                  70, 105, 95, 70, 90, 105, 70, 75, 102, 100,\n",
    "                  100, 95, 90, 80, 90, 80, 100, 105, 70, 65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fit the k nearest neighbors regression model to predict the bit per minute of a song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but first lets see the results we got from runing the model with only loudness as data from our notes.\n",
    "Unweighted Accuracy: -0.18 (+/- 0.66)\n",
    "Weighted Accuracy: 0.11 (+/- 0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: -0.42 (+/- 0.78)\n",
      "Weighted Accuracy: -0.26 (+/- 0.74)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors= 10)\n",
    "X = music[['loudness', 'duration']]\n",
    "Y = music.bpm\n",
    "knn.fit(X, Y)\n",
    "\n",
    "knn_w = neighbors.KNeighborsRegressor(n_neighbors= 10, weights= 'distance')\n",
    "X = music[['loudness', 'duration']]\n",
    "Y = music.bpm\n",
    "knn_w.fit(X, Y)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(knn, X, Y, cv=5)\n",
    "print(\"Unweighted Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "score_w = cross_val_score(knn_w, X, Y, cv=5)\n",
    "print(\"Weighted Accuracy: %0.2f (+/- %0.2f)\" % (score_w.mean(), score_w.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score variance in the unweighted model increased from 0.66 to .078 while the variance for the weighted decreased from 0.94 to 0.74.But both the score means seem to have improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets now re-run the models with k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: -0.32 (+/- 0.59)\n",
      "Weighted Accuracy: -0.23 (+/- 0.60)\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsRegressor(n_neighbors= 20)\n",
    "X = music[['loudness', 'duration']]\n",
    "Y = music.bpm\n",
    "knn.fit(X, Y)\n",
    "\n",
    "knn_w = neighbors.KNeighborsRegressor(n_neighbors= 20, weights= 'distance')\n",
    "X = music[['loudness', 'duration']]\n",
    "Y = music.bpm\n",
    "knn_w.fit(X, Y)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(knn, X, Y, cv=5)\n",
    "print(\"Unweighted Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "score_w = cross_val_score(knn_w, X, Y, cv=5)\n",
    "print(\"Weighted Accuracy: %0.2f (+/- %0.2f)\" % (score_w.mean(), score_w.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both the unweighted and weighted models when k is getting larger, the variance of the scores got smaller while the mean scores suffered more.It Was variance, accuracy tradeoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
